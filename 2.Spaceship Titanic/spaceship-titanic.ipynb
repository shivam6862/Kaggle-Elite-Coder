{"cells":[{"cell_type":"markdown","metadata":{},"source":["# IMPORTING PACKAGE üìöüì¶"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.725304Z","iopub.status.busy":"2023-10-24T13:12:50.724497Z","iopub.status.idle":"2023-10-24T13:12:50.736262Z","shell.execute_reply":"2023-10-24T13:12:50.735159Z","shell.execute_reply.started":"2023-10-24T13:12:50.725257Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from scipy.stats import norm, skew\n","from scipy import stats \n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC, LinearSVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.cluster import KMeans\n","import math\n","from sklearn.metrics import accuracy_score\n","\n","from xgboost import XGBClassifier\n","\n","from lightgbm import LGBMClassifier\n","from catboost import CatBoostClassifier"]},{"cell_type":"markdown","metadata":{},"source":["# DATA OVERVIEWS üìä üìä"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.740082Z","iopub.status.busy":"2023-10-24T13:12:50.738932Z","iopub.status.idle":"2023-10-24T13:12:50.813927Z","shell.execute_reply":"2023-10-24T13:12:50.812881Z","shell.execute_reply.started":"2023-10-24T13:12:50.740030Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"../input/spaceship-titanic/train.csv\")\n","test_df = pd.read_csv('../input/spaceship-titanic/test.csv')\n","sample_submission = pd.read_csv(\"../input/spaceship-titanic/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.816677Z","iopub.status.busy":"2023-10-24T13:12:50.815840Z","iopub.status.idle":"2023-10-24T13:12:50.831076Z","shell.execute_reply":"2023-10-24T13:12:50.829991Z","shell.execute_reply.started":"2023-10-24T13:12:50.816630Z"},"trusted":true},"outputs":[],"source":["train_df['VIP'] = train_df['VIP'].map({True: 1, False: 0})\n","train_df['CryoSleep'] = train_df['CryoSleep'].map({True: 1, False: 0})\n","train_df['Transported'] = train_df['Transported'].map({True: 1, False: 0})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.834931Z","iopub.status.busy":"2023-10-24T13:12:50.834102Z","iopub.status.idle":"2023-10-24T13:12:50.859498Z","shell.execute_reply":"2023-10-24T13:12:50.858522Z","shell.execute_reply.started":"2023-10-24T13:12:50.834882Z"},"trusted":true},"outputs":[],"source":["train_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.861668Z","iopub.status.busy":"2023-10-24T13:12:50.860991Z","iopub.status.idle":"2023-10-24T13:12:50.877746Z","shell.execute_reply":"2023-10-24T13:12:50.876387Z","shell.execute_reply.started":"2023-10-24T13:12:50.861633Z"},"trusted":true},"outputs":[],"source":["test_df['VIP'] = test_df['VIP'].map({True: 1, False: 0})\n","test_df['CryoSleep'] = test_df['CryoSleep'].map({True: 1, False: 0})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.880401Z","iopub.status.busy":"2023-10-24T13:12:50.879291Z","iopub.status.idle":"2023-10-24T13:12:50.907882Z","shell.execute_reply":"2023-10-24T13:12:50.906555Z","shell.execute_reply.started":"2023-10-24T13:12:50.880364Z"},"trusted":true},"outputs":[],"source":["test_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.912374Z","iopub.status.busy":"2023-10-24T13:12:50.911961Z","iopub.status.idle":"2023-10-24T13:12:50.927873Z","shell.execute_reply":"2023-10-24T13:12:50.926542Z","shell.execute_reply.started":"2023-10-24T13:12:50.912303Z"},"trusted":true},"outputs":[],"source":["sample_submission.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.933121Z","iopub.status.busy":"2023-10-24T13:12:50.932598Z","iopub.status.idle":"2023-10-24T13:12:50.955874Z","shell.execute_reply":"2023-10-24T13:12:50.954408Z","shell.execute_reply.started":"2023-10-24T13:12:50.933072Z"},"trusted":true},"outputs":[],"source":["train_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.958604Z","iopub.status.busy":"2023-10-24T13:12:50.958111Z","iopub.status.idle":"2023-10-24T13:12:50.966853Z","shell.execute_reply":"2023-10-24T13:12:50.965527Z","shell.execute_reply.started":"2023-10-24T13:12:50.958559Z"},"trusted":true},"outputs":[],"source":["column_names = train_df.columns\n","column_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:50.968949Z","iopub.status.busy":"2023-10-24T13:12:50.968599Z","iopub.status.idle":"2023-10-24T13:12:51.020961Z","shell.execute_reply":"2023-10-24T13:12:51.019675Z","shell.execute_reply.started":"2023-10-24T13:12:50.968920Z"},"trusted":true},"outputs":[],"source":["train_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.023267Z","iopub.status.busy":"2023-10-24T13:12:51.022821Z","iopub.status.idle":"2023-10-24T13:12:51.071948Z","shell.execute_reply":"2023-10-24T13:12:51.070633Z","shell.execute_reply.started":"2023-10-24T13:12:51.023225Z"},"trusted":true},"outputs":[],"source":["train_df.describe(include=['O'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.073880Z","iopub.status.busy":"2023-10-24T13:12:51.073552Z","iopub.status.idle":"2023-10-24T13:12:51.101973Z","shell.execute_reply":"2023-10-24T13:12:51.100674Z","shell.execute_reply.started":"2023-10-24T13:12:51.073853Z"},"trusted":true},"outputs":[],"source":["concatenated_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n","concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.104156Z","iopub.status.busy":"2023-10-24T13:12:51.103774Z","iopub.status.idle":"2023-10-24T13:12:51.113385Z","shell.execute_reply":"2023-10-24T13:12:51.112096Z","shell.execute_reply.started":"2023-10-24T13:12:51.104123Z"},"trusted":true},"outputs":[],"source":["y_train = train_df[\"Transported\"]\n","y_train.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.115628Z","iopub.status.busy":"2023-10-24T13:12:51.115236Z","iopub.status.idle":"2023-10-24T13:12:51.138981Z","shell.execute_reply":"2023-10-24T13:12:51.137730Z","shell.execute_reply.started":"2023-10-24T13:12:51.115596Z"},"trusted":true},"outputs":[],"source":["all_data_na = (concatenated_df.isnull().sum() / len(concatenated_df)) * 100\n","all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:20]\n","missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n","# missing_data"]},{"cell_type":"markdown","metadata":{},"source":["# Analysis of cabin data üîçüîç"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.141346Z","iopub.status.busy":"2023-10-24T13:12:51.140509Z","iopub.status.idle":"2023-10-24T13:12:51.559236Z","shell.execute_reply":"2023-10-24T13:12:51.557776Z","shell.execute_reply.started":"2023-10-24T13:12:51.141275Z"},"trusted":true},"outputs":[],"source":["# Sample Cabin data\n","cabin_data = train_df[\"Cabin\"]\n","\n","# Create a DataFrame from the cabin data\n","cabin_df = pd.DataFrame({'Cabin': cabin_data})\n","\n","# Extract the first string before the first \"/\"\n","cabin_df['FirstString'] = cabin_df['Cabin'].str.split('/').str[0]\n","\n","# Add the 'Transported' column to the cabin_df DataFrame\n","cabin_df['Transported'] = train_df['Transported']\n","\n","# Calculate unique first strings frequencies for Transported == 1 and Transported == 0\n","unique_first_strings_1 = cabin_df[cabin_df['Transported'] == 1]['FirstString'].value_counts()\n","unique_first_strings_0 = cabin_df[cabin_df['Transported'] == 0]['FirstString'].value_counts()\n","\n","# Plotting\n","plt.figure(figsize=(6, 4))\n","unique_first_strings_1.plot(kind='bar', color='b', width=0.4, position=0, label='Transported=1')\n","unique_first_strings_0.plot(kind='bar', color='g', width=0.4, position=1, label='Transported=0')\n","plt.xlabel('First String in Cabin')\n","plt.ylabel('Number of People')\n","plt.title('Number of People Transported Based on Unique First Strings in Cabin')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.562237Z","iopub.status.busy":"2023-10-24T13:12:51.561191Z","iopub.status.idle":"2023-10-24T13:12:51.638078Z","shell.execute_reply":"2023-10-24T13:12:51.636802Z","shell.execute_reply.started":"2023-10-24T13:12:51.562187Z"},"trusted":true},"outputs":[],"source":["concatenated_df['cabin_ids'] = concatenated_df['Cabin'].str.split('/').str[0]\n","concatenated_df['cabin_place'] = concatenated_df['Cabin'].str.split('/').str[2]\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Drop of columns ‚ùå"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.646337Z","iopub.status.busy":"2023-10-24T13:12:51.645876Z","iopub.status.idle":"2023-10-24T13:12:51.680120Z","shell.execute_reply":"2023-10-24T13:12:51.678956Z","shell.execute_reply.started":"2023-10-24T13:12:51.646287Z"},"trusted":true},"outputs":[],"source":["concatenated_df['PassengerId_group'] = concatenated_df['PassengerId'].str.split('_').str[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.682680Z","iopub.status.busy":"2023-10-24T13:12:51.682171Z","iopub.status.idle":"2023-10-24T13:12:51.742151Z","shell.execute_reply":"2023-10-24T13:12:51.740935Z","shell.execute_reply.started":"2023-10-24T13:12:51.682635Z"},"trusted":true},"outputs":[],"source":["concatenated_df['Name_surname'] = concatenated_df['Name'].str.split(' ').str[-1]\n","concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.744445Z","iopub.status.busy":"2023-10-24T13:12:51.743941Z","iopub.status.idle":"2023-10-24T13:12:51.778071Z","shell.execute_reply":"2023-10-24T13:12:51.776684Z","shell.execute_reply.started":"2023-10-24T13:12:51.744397Z"},"trusted":true},"outputs":[],"source":["# List of features to be dropped\n","features_to_drop = [\"PassengerId\",\"Cabin\",\"Name\"]\n","\n","# Drop the specified features from the concatenated DataFrame\n","concatenated_df.drop(features_to_drop, axis=1, inplace=True)\n","\n","# Now, concatenated_df does not contain the specified features\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Row with atleast one nan üß©üß©"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.779970Z","iopub.status.busy":"2023-10-24T13:12:51.779617Z","iopub.status.idle":"2023-10-24T13:12:51.833426Z","shell.execute_reply":"2023-10-24T13:12:51.832266Z","shell.execute_reply.started":"2023-10-24T13:12:51.779942Z"},"trusted":true},"outputs":[],"source":["### Number of cell null\n","n=1\n","# Find rows where at least n out of 13 columns have missing data\n","rows_with_missing_data = train_df[train_df.isnull().sum(axis=1) >= n]\n","\n","# Print the result\n","rows_with_missing_data"]},{"cell_type":"markdown","metadata":{},"source":["# Filling the NAN cells üõ†Ô∏è üõ†Ô∏è"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.835631Z","iopub.status.busy":"2023-10-24T13:12:51.835272Z","iopub.status.idle":"2023-10-24T13:12:51.846639Z","shell.execute_reply":"2023-10-24T13:12:51.845466Z","shell.execute_reply.started":"2023-10-24T13:12:51.835602Z"},"trusted":true},"outputs":[],"source":["concatenated_df[\"expenses\"]=concatenated_df[\"RoomService\"]+concatenated_df[\"FoodCourt\"]+concatenated_df[\"ShoppingMall\"]+concatenated_df[\"Spa\"]+concatenated_df[\"VRDeck\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.848510Z","iopub.status.busy":"2023-10-24T13:12:51.848151Z","iopub.status.idle":"2023-10-24T13:12:51.882355Z","shell.execute_reply":"2023-10-24T13:12:51.881062Z","shell.execute_reply.started":"2023-10-24T13:12:51.848481Z"},"trusted":true},"outputs":[],"source":["concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.884411Z","iopub.status.busy":"2023-10-24T13:12:51.884047Z","iopub.status.idle":"2023-10-24T13:12:51.895546Z","shell.execute_reply":"2023-10-24T13:12:51.894382Z","shell.execute_reply.started":"2023-10-24T13:12:51.884380Z"},"trusted":true},"outputs":[],"source":["# Function to fill NaN values in HomePlanet and Destination column\n","def fill_HomePlanet_Destination(row, column_name):\n","    if pd.notnull(row[column_name]):\n","        return row[column_name]\n","    group = concatenated_df.loc[concatenated_df['PassengerId_group'] == row['PassengerId_group'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['Name_surname'] == row['Name_surname'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['cabin_ids'] == row['cabin_ids'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    print(concatenated_df[column_name].mode()[0])\n","    return concatenated_df[column_name].mode()[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:51.897799Z","iopub.status.busy":"2023-10-24T13:12:51.897290Z","iopub.status.idle":"2023-10-24T13:12:53.851419Z","shell.execute_reply":"2023-10-24T13:12:53.850228Z","shell.execute_reply.started":"2023-10-24T13:12:51.897763Z"},"trusted":true},"outputs":[],"source":["\n","# Apply the function to fill NaN values in HomePlanet and Destination column\n","column_name = 'HomePlanet'\n","print(concatenated_df[column_name].isnull().sum())\n","concatenated_df[column_name] = concatenated_df.apply(lambda row: fill_HomePlanet_Destination(row, column_name), axis=1)\n","print(concatenated_df[column_name].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:53.856124Z","iopub.status.busy":"2023-10-24T13:12:53.855745Z","iopub.status.idle":"2023-10-24T13:12:55.681483Z","shell.execute_reply":"2023-10-24T13:12:55.680221Z","shell.execute_reply.started":"2023-10-24T13:12:53.856094Z"},"trusted":true},"outputs":[],"source":["\n","# Apply the function to fill NaN values in HomePlanet and Destination column\n","column_name = 'Destination'\n","print(concatenated_df[column_name].isnull().sum())\n","concatenated_df[column_name] = concatenated_df.apply(lambda row: fill_HomePlanet_Destination(row, column_name), axis=1)\n","print(concatenated_df[column_name].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:55.683552Z","iopub.status.busy":"2023-10-24T13:12:55.683192Z","iopub.status.idle":"2023-10-24T13:12:55.972681Z","shell.execute_reply":"2023-10-24T13:12:55.971292Z","shell.execute_reply.started":"2023-10-24T13:12:55.683522Z"},"trusted":true},"outputs":[],"source":["# Calculate mean values for each group defined by the features\n","mean_age_by_homeplanet = concatenated_df.groupby([\"HomePlanet\", \"Destination\"])['Age'].mean()\n","\n","# Function to fill NaN values in 'Age' column\n","def fill_age(row):\n","    if pd.notnull(row['Age']):\n","        return row['Age']\n","    homeplanet_features = (row['HomePlanet'], row['Destination'])\n","    if homeplanet_features in mean_age_by_homeplanet.index:\n","        return mean_age_by_homeplanet.loc[homeplanet_features]\n","    else:\n","        print(\"!!Not present!!\")\n","        return concatenated_df['Age'].mean()  # Fill with overall mean if no matching group is found\n","\n","# Apply the function to fill NaN values in 'Age' column\n","print(concatenated_df['Age'].isnull().sum())\n","concatenated_df['Age'] = concatenated_df.apply(fill_age, axis=1)\n","print(concatenated_df['Age'].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:55.977146Z","iopub.status.busy":"2023-10-24T13:12:55.976774Z","iopub.status.idle":"2023-10-24T13:12:56.296537Z","shell.execute_reply":"2023-10-24T13:12:56.295272Z","shell.execute_reply.started":"2023-10-24T13:12:55.977117Z"},"trusted":true},"outputs":[],"source":["# Set CryoSleep values based on RoomService and existing CryoSleep values\n","concatenated_df['CryoSleep'] = concatenated_df.apply(lambda row: 1 if pd.isnull(row['CryoSleep']) and row['RoomService'] == 0 else (0 if pd.isnull(row['CryoSleep']) else row['CryoSleep']), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:56.299414Z","iopub.status.busy":"2023-10-24T13:12:56.298225Z","iopub.status.idle":"2023-10-24T13:12:58.333091Z","shell.execute_reply":"2023-10-24T13:12:58.331709Z","shell.execute_reply.started":"2023-10-24T13:12:56.299363Z"},"trusted":true},"outputs":[],"source":["# Function to fill NaN values in VIP column\n","def fill_VIP(row):\n","    if pd.notnull(row['VIP']):\n","        return row['VIP']\n","    group = concatenated_df.loc[concatenated_df['PassengerId_group'] == row['PassengerId_group'], 'VIP']\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['Name_surname'] == row['Name_surname'], 'VIP']\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['cabin_ids'] == row['cabin_ids'], 'VIP']\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    print(row['expenses']>1150)\n","    return row['expenses'] > 1150\n","\n","# Apply the function to fill NaN values in VIP column\n","print(concatenated_df['VIP'].isnull().sum())\n","concatenated_df['VIP'] = concatenated_df.apply(fill_VIP, axis=1)\n","print(concatenated_df['VIP'].isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:58.335148Z","iopub.status.busy":"2023-10-24T13:12:58.334652Z","iopub.status.idle":"2023-10-24T13:12:58.356914Z","shell.execute_reply":"2023-10-24T13:12:58.355666Z","shell.execute_reply.started":"2023-10-24T13:12:58.335116Z"},"trusted":true},"outputs":[],"source":["concatenated_df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:12:58.359247Z","iopub.status.busy":"2023-10-24T13:12:58.358248Z","iopub.status.idle":"2023-10-24T13:13:16.428540Z","shell.execute_reply":"2023-10-24T13:13:16.427309Z","shell.execute_reply.started":"2023-10-24T13:12:58.359212Z"},"trusted":true},"outputs":[],"source":["# Function to fill NaN values in specified columns\n","def fill_column(row, column_name):\n","    if pd.notnull(row[column_name]):\n","        return row[column_name]\n","    group = concatenated_df.loc[concatenated_df['PassengerId_group'] == row['PassengerId_group'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['Name_surname'] == row['Name_surname'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    group = concatenated_df.loc[concatenated_df['cabin_ids'] == row['cabin_ids'], column_name]\n","    if not group.empty and pd.notnull(group.values[0]):\n","        return group.values[0]\n","    if column_name == \"expenses\":\n","        return 130\n","    print(column_name)\n","    return 128\n","\n","# List of columns to fill NaN values\n","columns_to_fill = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck' ,'expenses']\n","\n","# Apply the function to fill NaN values in specified columns\n","for column in columns_to_fill:\n","    concatenated_df[column] = concatenated_df.apply(lambda row: fill_column(row, column), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.430768Z","iopub.status.busy":"2023-10-24T13:13:16.430257Z","iopub.status.idle":"2023-10-24T13:13:16.459963Z","shell.execute_reply":"2023-10-24T13:13:16.458743Z","shell.execute_reply.started":"2023-10-24T13:13:16.430725Z"},"trusted":true},"outputs":[],"source":["# Fill NaN values in 'Name_surname','cabin_ids',cabin_place column with 'Unknown'\n","concatenated_df['Name_surname'] = concatenated_df['Name_surname'].fillna('Unknown')\n","concatenated_df['cabin_ids'] = concatenated_df['cabin_ids'].fillna('G')\n","concatenated_df['cabin_place'] = concatenated_df['cabin_place'].fillna('S')\n","print(concatenated_df.isnull().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.461933Z","iopub.status.busy":"2023-10-24T13:13:16.461461Z","iopub.status.idle":"2023-10-24T13:13:16.492003Z","shell.execute_reply":"2023-10-24T13:13:16.490643Z","shell.execute_reply.started":"2023-10-24T13:13:16.461891Z"},"trusted":true},"outputs":[],"source":["# List of features to be dropped\n","# features_to_drop = [\"expenses\",\"PassengerId_group\"]\n","features_to_drop = [\"PassengerId_group\"]\n","\n","# Drop the specified features from the concatenated DataFrame\n","concatenated_df.drop(features_to_drop, axis=1, inplace=True)\n","\n","# Now, concatenated_df does not contain the specified features\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Changing according to need (LabelEncoder) üîÑ üîÑ üîÑ"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.496199Z","iopub.status.busy":"2023-10-24T13:13:16.495816Z","iopub.status.idle":"2023-10-24T13:13:16.564981Z","shell.execute_reply":"2023-10-24T13:13:16.563743Z","shell.execute_reply.started":"2023-10-24T13:13:16.496170Z"},"trusted":true},"outputs":[],"source":["label_encoder = LabelEncoder()\n","\n","categorical_columns = concatenated_df.select_dtypes(include=['O']).columns.tolist()\n","\n","for column in categorical_columns:\n","    concatenated_df[column] = label_encoder.fit_transform(concatenated_df[column])\n","    \n","concatenated_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.567423Z","iopub.status.busy":"2023-10-24T13:13:16.566936Z","iopub.status.idle":"2023-10-24T13:13:16.945390Z","shell.execute_reply":"2023-10-24T13:13:16.944287Z","shell.execute_reply.started":"2023-10-24T13:13:16.567380Z"},"trusted":true},"outputs":[],"source":["# Plot a histogram of the 'Age' column\n","plt.figure(figsize=(6, 4))\n","plt.hist(concatenated_df[\"Age\"], bins=30, color='skyblue', edgecolor='black')\n","plt.title('Number of People vs. Age')\n","plt.xlabel('Age')\n","plt.ylabel('Number of People')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.947451Z","iopub.status.busy":"2023-10-24T13:13:16.946976Z","iopub.status.idle":"2023-10-24T13:13:16.979909Z","shell.execute_reply":"2023-10-24T13:13:16.978552Z","shell.execute_reply.started":"2023-10-24T13:13:16.947414Z"},"trusted":true},"outputs":[],"source":["# Define bins and labels for age groups\n","bins = [0, 12, 17, 25, 30, 50, float('inf')]\n","labels = [0, 1, 2, 3, 2, 1]\n","\n","# Create a new column 'AgeGroup' based on the 'Age' column\n","concatenated_df['AgeGroup'] = pd.cut(concatenated_df['Age'], bins=bins, labels=labels, right=False,ordered=False)\n","\n","concatenated_df.drop('Age', axis=1, inplace=True)\n","\n","# Print the DataFrame with the new 'AgeGroup' column\n","concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:16.981934Z","iopub.status.busy":"2023-10-24T13:13:16.981494Z","iopub.status.idle":"2023-10-24T13:13:17.695094Z","shell.execute_reply":"2023-10-24T13:13:17.693925Z","shell.execute_reply.started":"2023-10-24T13:13:16.981898Z"},"trusted":true},"outputs":[],"source":["# Plot a histogram of the 'Age' column\n","plt.figure(figsize=(6, 4))\n","plt.hist(concatenated_df[\"AgeGroup\"], bins=30, color='skyblue', edgecolor='black')\n","plt.title('Number of People vs. AgeGroup')\n","plt.xlabel('Age')\n","plt.ylabel('Number of People')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Checking skewness of dataset ‚Ü™Ô∏è ‚Ü™Ô∏è"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:17.696871Z","iopub.status.busy":"2023-10-24T13:13:17.696454Z","iopub.status.idle":"2023-10-24T13:13:17.733501Z","shell.execute_reply":"2023-10-24T13:13:17.732309Z","shell.execute_reply.started":"2023-10-24T13:13:17.696841Z"},"trusted":true},"outputs":[],"source":["numeric_feats = concatenated_df.dtypes[concatenated_df.dtypes != \"object\"].index\n","skewed_feats = concatenated_df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n","print(\"\\nSkew in numerical features: \\n\")\n","skewness = pd.DataFrame({'Skew' :skewed_feats})\n","skewness.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:17.735379Z","iopub.status.busy":"2023-10-24T13:13:17.735048Z","iopub.status.idle":"2023-10-24T13:13:19.721158Z","shell.execute_reply":"2023-10-24T13:13:19.720270Z","shell.execute_reply.started":"2023-10-24T13:13:17.735350Z"},"trusted":true},"outputs":[],"source":["# Convert the expenses data to a NumPy array\n","expenses_data = np.array(concatenated_df[\"expenses\"])\n","print(expenses_data)\n","# Calculate WCSS for different values of k\n","wcss = []\n","for i in range(1, 15):\n","    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","    kmeans.fit(expenses_data.reshape(-1, 1))\n","    wcss.append(kmeans.inertia_)\n","\n","# Plot the Elbow Method graph\n","plt.figure(figsize=(6, 4))\n","plt.plot(range(1, 15), wcss, marker='o', linestyle='--')\n","plt.title('Elbow Method')\n","plt.xlabel('Number of Clusters')\n","plt.ylabel('WCSS')  # Within-cluster sum of squares\n","plt.xticks(np.arange(1, 15, 1))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:19.723264Z","iopub.status.busy":"2023-10-24T13:13:19.722657Z","iopub.status.idle":"2023-10-24T13:13:19.729729Z","shell.execute_reply":"2023-10-24T13:13:19.728609Z","shell.execute_reply.started":"2023-10-24T13:13:19.723229Z"},"trusted":true},"outputs":[],"source":["# Find the optimal number of clusters using the Elbow Method\n","optimal_num_clusters = np.argmin(np.diff(wcss)) + 1\n","\n","print(\"Optimal number of clusters:\", optimal_num_clusters)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:19.731892Z","iopub.status.busy":"2023-10-24T13:13:19.731556Z","iopub.status.idle":"2023-10-24T13:13:19.794287Z","shell.execute_reply":"2023-10-24T13:13:19.793410Z","shell.execute_reply.started":"2023-10-24T13:13:19.731863Z"},"trusted":true},"outputs":[],"source":["optimal_clusters_curr=5\n","optimal_clusters_curr"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:19.796470Z","iopub.status.busy":"2023-10-24T13:13:19.795836Z","iopub.status.idle":"2023-10-24T13:13:20.827686Z","shell.execute_reply":"2023-10-24T13:13:20.826700Z","shell.execute_reply.started":"2023-10-24T13:13:19.796435Z"},"trusted":true},"outputs":[],"source":["# Convert the expenses data to a NumPy array\n","expenses_data = np.array(concatenated_df[\"expenses\"])\n","\n","# Reshape the expenses data to be a 2D array\n","expenses_data_reshaped = expenses_data.reshape(-1, 1)\n","\n","# Define the optimal number of clusters (found using the Elbow Method)\n","optimal_clusters = optimal_clusters_curr\n","\n","# Apply KMeans clustering with the optimal number of clusters\n","kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","cluster_labels = kmeans.fit_predict(expenses_data_reshaped)\n","\n","# Visualize the clusters and data points\n","plt.figure(figsize=(6, 4))\n","for i in range(optimal_clusters):\n","    plt.scatter(expenses_data_reshaped[cluster_labels == i], [i] * len(expenses_data_reshaped[cluster_labels == i]), label=f'Cluster {i+1}')\n","\n","plt.scatter(kmeans.cluster_centers_, np.arange(optimal_clusters), color='red', marker='X', label='Centroids')\n","plt.xlabel('expenses')\n","plt.ylabel('Cluster')\n","plt.title('Clustering of Expenses Data')\n","plt.legend()\n","plt.show()\n","\n","# Output the cluster labels for each data point\n","print(\"Cluster Labels:\")\n","print(cluster_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:20.829965Z","iopub.status.busy":"2023-10-24T13:13:20.829276Z","iopub.status.idle":"2023-10-24T13:13:20.932233Z","shell.execute_reply":"2023-10-24T13:13:20.931201Z","shell.execute_reply.started":"2023-10-24T13:13:20.829928Z"},"trusted":true},"outputs":[],"source":["# Assuming you have determined the optimal number of clusters (optimal_clusters) using the Elbow Method\n","optimal_clusters = optimal_clusters_curr  # Replace this with the actual optimal number of clusters\n","\n","# expenses data (assuming you already have this data)\n","expenses_data = np.array(concatenated_df[\"expenses\"])\n","\n","# Reshape the expenses data to be a 2D array\n","expenses_data_reshaped = expenses_data.reshape(-1, 1)\n","\n","# Apply KMeans clustering with the optimal number of clusters\n","kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","cluster_labels = kmeans.fit_predict(expenses_data_reshaped)\n","\n","# Add the cluster labels as a new column to the DataFrame\n","concatenated_df[\"expenses_cluster\"] = cluster_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:20.934827Z","iopub.status.busy":"2023-10-24T13:13:20.934053Z","iopub.status.idle":"2023-10-24T13:13:21.394840Z","shell.execute_reply":"2023-10-24T13:13:21.393652Z","shell.execute_reply.started":"2023-10-24T13:13:20.934782Z"},"trusted":true},"outputs":[],"source":["# Columns to fill with cluster labels\n","columns_to_fill = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n","\n","# Assuming you have determined the optimal number of clusters (optimal_clusters) using the Elbow Method\n","optimal_clusters = optimal_clusters_curr  # Replace this with the actual optimal number of clusters\n","\n","# Iterate through columns and apply clustering\n","for column in columns_to_fill:\n","    # Get the data for the current column\n","    column_data = np.array(concatenated_df[column])\n","    column_data_reshaped = column_data.reshape(-1, 1)\n","    \n","    # Apply KMeans clustering with the optimal number of clusters\n","    kmeans = KMeans(n_clusters=optimal_clusters, init='k-means++', max_iter=300, n_init=10, random_state=0)\n","    cluster_labels = kmeans.fit_predict(column_data_reshaped)\n","    \n","    # Add the cluster labels as a new column to the DataFrame\n","    concatenated_df[f\"{column}_cluster\"] = cluster_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:21.405278Z","iopub.status.busy":"2023-10-24T13:13:21.404883Z","iopub.status.idle":"2023-10-24T13:13:21.429455Z","shell.execute_reply":"2023-10-24T13:13:21.428226Z","shell.execute_reply.started":"2023-10-24T13:13:21.405248Z"},"trusted":true},"outputs":[],"source":["# List of features to be dropped\n","features_to_drop = [\"expenses\",'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n","\n","# Drop the specified features from the concatenated DataFrame\n","concatenated_df.drop(features_to_drop, axis=1, inplace=True)\n","\n","# Now, concatenated_df does not contain the specified features\n","concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:21.431601Z","iopub.status.busy":"2023-10-24T13:13:21.431089Z","iopub.status.idle":"2023-10-24T13:13:21.452467Z","shell.execute_reply":"2023-10-24T13:13:21.451173Z","shell.execute_reply.started":"2023-10-24T13:13:21.431556Z"},"trusted":true},"outputs":[],"source":["concatenated_df.drop(\"expenses_cluster\", axis=1, inplace=True)\n","concatenated_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:21.454753Z","iopub.status.busy":"2023-10-24T13:13:21.454241Z","iopub.status.idle":"2023-10-24T13:13:21.480656Z","shell.execute_reply":"2023-10-24T13:13:21.479270Z","shell.execute_reply.started":"2023-10-24T13:13:21.454708Z"},"trusted":true},"outputs":[],"source":["concatenated_df.drop(\"Name_surname\", axis=1, inplace=True)\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Bar chat for all columns üìäüìà"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:21.482627Z","iopub.status.busy":"2023-10-24T13:13:21.482196Z","iopub.status.idle":"2023-10-24T13:13:27.881649Z","shell.execute_reply":"2023-10-24T13:13:27.880092Z","shell.execute_reply.started":"2023-10-24T13:13:21.482593Z"},"trusted":true},"outputs":[],"source":["# Assuming univalue_columns is a list of column names containing unique values\n","columns_list = concatenated_df.columns\n","\n","# Set up subplots\n","fig, axs = plt.subplots(len(columns_list), 2, figsize=(16, 4 * len(columns_list)))\n","\n","for i, column in enumerate(columns_list):\n","    count_labels = concatenated_df[column].value_counts()\n","\n","    # Plot pie chart\n","    axs[i, 0].pie(count_labels, labels=count_labels.index, autopct='%.1f%%', shadow=True)\n","    axs[i, 0].set_title(f'Pie Chart of {column} Counts')\n","\n","    # Plot countplot\n","    sns.countplot(data=concatenated_df, x=column, hue='Transported', palette='pastel', ax=axs[i, 1])\n","    axs[i, 1].set_title(f'Bar Graph of {column} Counts')\n","    axs[i, 1].set_ylabel('Count')  # Assuming you want a y-label for the countplot\n","\n","# Adjust layout and show plots\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.884019Z","iopub.status.busy":"2023-10-24T13:13:27.883528Z","iopub.status.idle":"2023-10-24T13:13:27.908614Z","shell.execute_reply":"2023-10-24T13:13:27.907190Z","shell.execute_reply.started":"2023-10-24T13:13:27.883978Z"},"trusted":true},"outputs":[],"source":["concatenated_df.drop('Transported', axis=1, inplace=True)\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Working with HomePlanet and  Destination üåçüõ∏"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.911080Z","iopub.status.busy":"2023-10-24T13:13:27.910578Z","iopub.status.idle":"2023-10-24T13:13:27.926302Z","shell.execute_reply":"2023-10-24T13:13:27.925022Z","shell.execute_reply.started":"2023-10-24T13:13:27.911034Z"},"trusted":true},"outputs":[],"source":["# Create binary columns for each unique class in the \"HomePlanet\" column\n","HomePlanet_dummies = pd.get_dummies(concatenated_df[\"HomePlanet\"])\n","\n","# Rename the columns to indicate the presence of specific classes\n","HomePlanet_dummies.columns = [\"HomePlanet\" + str(class_num) for class_num in HomePlanet_dummies.columns]\n","\n","# Concatenate the binary columns with the original DataFrame\n","concatenated_df = pd.concat([concatenated_df, HomePlanet_dummies], axis=1)\n","\n","# Drop the original \"HomePlanet\" column\n","concatenated_df.drop(\"HomePlanet\", axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.928072Z","iopub.status.busy":"2023-10-24T13:13:27.927720Z","iopub.status.idle":"2023-10-24T13:13:27.940705Z","shell.execute_reply":"2023-10-24T13:13:27.939209Z","shell.execute_reply.started":"2023-10-24T13:13:27.928044Z"},"trusted":true},"outputs":[],"source":["# Create binary columns for each unique class in the \"Destination\" column\n","Destination_dummies = pd.get_dummies(concatenated_df[\"Destination\"])\n","\n","# Rename the columns to indicate the presence of specific classes\n","Destination_dummies.columns = [\"Destination\" + str(class_num) for class_num in Destination_dummies.columns]\n","\n","# Concatenate the binary columns with the original DataFrame\n","concatenated_df = pd.concat([concatenated_df, Destination_dummies], axis=1)\n","\n","# Drop the original \"Destination\" column\n","concatenated_df.drop(\"Destination\", axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.942689Z","iopub.status.busy":"2023-10-24T13:13:27.942311Z","iopub.status.idle":"2023-10-24T13:13:27.970126Z","shell.execute_reply":"2023-10-24T13:13:27.968778Z","shell.execute_reply.started":"2023-10-24T13:13:27.942658Z"},"trusted":true},"outputs":[],"source":["# Print the updated DataFrame\n","concatenated_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset extract üìëüìë"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.972056Z","iopub.status.busy":"2023-10-24T13:13:27.971639Z","iopub.status.idle":"2023-10-24T13:13:27.983141Z","shell.execute_reply":"2023-10-24T13:13:27.981814Z","shell.execute_reply.started":"2023-10-24T13:13:27.972022Z"},"trusted":true},"outputs":[],"source":["# Get the index where the train and test data were originally separated\n","train_data_index = len(train_df)\n","test_data_index = len(concatenated_df) - len(test_df)\n","\n","# Split the concatenated data back into train and test sets\n","X_train = concatenated_df[:train_data_index]\n","X_test = concatenated_df[test_data_index:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:27.987707Z","iopub.status.busy":"2023-10-24T13:13:27.987304Z","iopub.status.idle":"2023-10-24T13:13:28.016203Z","shell.execute_reply":"2023-10-24T13:13:28.014738Z","shell.execute_reply.started":"2023-10-24T13:13:27.987676Z"},"trusted":true},"outputs":[],"source":["X_train.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.019088Z","iopub.status.busy":"2023-10-24T13:13:28.018716Z","iopub.status.idle":"2023-10-24T13:13:28.030051Z","shell.execute_reply":"2023-10-24T13:13:28.028747Z","shell.execute_reply.started":"2023-10-24T13:13:28.019059Z"},"trusted":true},"outputs":[],"source":["y_train.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.032474Z","iopub.status.busy":"2023-10-24T13:13:28.031994Z","iopub.status.idle":"2023-10-24T13:13:28.055799Z","shell.execute_reply":"2023-10-24T13:13:28.054531Z","shell.execute_reply.started":"2023-10-24T13:13:28.032431Z"},"trusted":true},"outputs":[],"source":["X_test.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Finding best value for model üîçüìè"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.058061Z","iopub.status.busy":"2023-10-24T13:13:28.057605Z","iopub.status.idle":"2023-10-24T13:13:28.068429Z","shell.execute_reply":"2023-10-24T13:13:28.066925Z","shell.execute_reply.started":"2023-10-24T13:13:28.058018Z"},"trusted":true},"outputs":[],"source":["# from sklearn.model_selection import train_test_split\n","\n","# # Split the data into training and validation sets\n","# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, stratify=y_train, train_size=0.8, test_size=0.2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.071636Z","iopub.status.busy":"2023-10-24T13:13:28.071047Z","iopub.status.idle":"2023-10-24T13:13:28.084288Z","shell.execute_reply":"2023-10-24T13:13:28.083327Z","shell.execute_reply.started":"2023-10-24T13:13:28.071578Z"},"trusted":true},"outputs":[],"source":["# # Importing necessary libraries for classifiers and grid search\n","# from sklearn.linear_model import LogisticRegression\n","# from sklearn.neighbors import KNeighborsClassifier\n","# from sklearn.svm import SVC\n","# from sklearn.ensemble import RandomForestClassifier\n","# from xgboost import XGBClassifier\n","# from lightgbm import LGBMClassifier\n","# from catboost import CatBoostClassifier\n","# from sklearn.naive_bayes import GaussianNB\n","\n","# # Classifiers dictionary containing different classifiers for classification tasks\n","# classifiers = {\n","#     \"LogisticRegression\": LogisticRegression(random_state=0),  # Logistic Regression Classifier\n","#     \"KNN\": KNeighborsClassifier(),  # K-Nearest Neighbors Classifier\n","# #     \"SVC\": SVC(random_state=0, probability=True),  # Support Vector Classifier\n","#     \"RandomForest\": RandomForestClassifier(random_state=0),  # Random Forest Classifier\n","#     \"XGBoost\": XGBClassifier(random_state=0, use_label_encoder=False, eval_metric='logloss'),  # XGBoost Classifier\n","#     \"LGBM\": LGBMClassifier(random_state=0),  # LightGBM Classifier\n","#     \"CatBoost\": CatBoostClassifier(random_state=0, verbose=False),  # CatBoost Classifier\n","#     \"NaiveBayes\": GaussianNB()  # Gaussian Naive Bayes Classifier\n","# }\n","\n","# # Grids for hyperparameter tuning using grid search for each classifier\n","# LR_grid = {\n","#     'penalty': ['l1', 'l2'],  # Regularization penalty (L1 or L2)\n","#     'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],  # Inverse of regularization strength\n","#     'max_iter': [50, 100, 150]  # Maximum number of iterations for the solver to converge\n","# }\n","\n","# KNN_grid = {\n","#     'n_neighbors': [3, 5, 7, 9],  # Number of neighbors to use for classification\n","#     'p': [1, 2]  # Power parameter for Minkowski distance (1 for Manhattan distance, 2 for Euclidean distance)\n","# }\n","\n","# SVC_grid = {\n","#     'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5],  # Regularization parameter\n","#     'kernel': ['linear', 'rbf'],  # Kernel type to be used in the algorithm\n","#     'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf' (scale: 1 / (n_features * X.var()) , auto: 1 / n_features)\n","# }\n","\n","# RF_grid = {\n","#     'n_estimators': [50, 100, 150, 200, 250, 300],  # Number of trees in the forest\n","#     'max_depth': [4, 6, 8, 10, 12]  # Maximum depth of the trees in the forest\n","# }\n","\n","# boosted_grid = {\n","#     'n_estimators': [50, 100, 150, 200],  # Number of boosting rounds\n","#     'max_depth': [4, 8, 12],  # Maximum depth of the boosting trees\n","#     'learning_rate': [0.05, 0.1, 0.15]  # Step size shrinkage to prevent overfitting\n","# }\n","\n","# NB_grid = {\n","#     'var_smoothing': [1e-10, 1e-9, 1e-8, 1e-7]  # Portion of the largest variance of all features to add to variances for calculation stability\n","# }\n","\n","# # Dictionary containing grids for each classifier\n","# grid = {\n","#     \"LogisticRegression\": LR_grid,\n","#     \"KNN\": KNN_grid,\n","# #     \"SVC\": SVC_grid,\n","#     \"RandomForest\": RF_grid,\n","#     \"XGBoost\": boosted_grid,\n","#     \"LGBM\": boosted_grid,\n","#     \"CatBoost\": boosted_grid,\n","#     \"NaiveBayes\": NB_grid\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.086913Z","iopub.status.busy":"2023-10-24T13:13:28.086433Z","iopub.status.idle":"2023-10-24T13:13:28.104051Z","shell.execute_reply":"2023-10-24T13:13:28.102746Z","shell.execute_reply.started":"2023-10-24T13:13:28.086867Z"},"trusted":true},"outputs":[],"source":["# import time\n","# import pandas as pd\n","# import numpy as np\n","# from sklearn.model_selection import GridSearchCV\n","\n","# # Initialize variables and data structures\n","# i = 0\n","# clf_best_params = classifiers.copy()  # Create a copy of the classifiers dictionary to store best parameters\n","# valid_scores = pd.DataFrame({'Classifer': classifiers.keys(), 'Validation accuracy': np.zeros(len(classifiers)),\n","#                             'Training time': np.zeros(len(classifiers))})  # Dataframe to store results\n","\n","# # Loop through each classifier and perform grid search with cross-validation\n","# for key, classifier in classifiers.items():\n","#     start = time.time()  # Record start time for training\n","\n","#     # Initialize GridSearchCV with the current classifier and corresponding parameter grid\n","#     clf = GridSearchCV(estimator=classifier, param_grid=grid[key], n_jobs=-1, cv=None)\n","\n","#     # Train the classifier and evaluate its performance on the validation set\n","#     clf.fit(X_train, y_train)\n","#     valid_scores.iloc[i, 1] = clf.score(X_test, y_test)  # Store validation accuracy\n","\n","#     # Save the best parameters found during grid search\n","#     clf_best_params[key] = clf.best_params_\n","\n","#     # Record the training time in minutes\n","#     stop = time.time()\n","#     valid_scores.iloc[i, 2] = np.round((stop - start) / 60, 2)\n","\n","#     # Print the current model's information\n","#     print('Model:', key)\n","#     print('Training time (mins):', valid_scores.iloc[i, 2])\n","#     print('Best Parameters:', clf.best_params_)  # Print the best parameters found by grid search\n","#     print('')\n","\n","#     i += 1  # Move to the next classifier in the loop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.106308Z","iopub.status.busy":"2023-10-24T13:13:28.105810Z","iopub.status.idle":"2023-10-24T13:13:28.122833Z","shell.execute_reply":"2023-10-24T13:13:28.121468Z","shell.execute_reply.started":"2023-10-24T13:13:28.106225Z"},"trusted":true},"outputs":[],"source":["# valid_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.124997Z","iopub.status.busy":"2023-10-24T13:13:28.124519Z","iopub.status.idle":"2023-10-24T13:13:28.134287Z","shell.execute_reply":"2023-10-24T13:13:28.132942Z","shell.execute_reply.started":"2023-10-24T13:13:28.124961Z"},"trusted":true},"outputs":[],"source":["# clf_best_params"]},{"cell_type":"markdown","metadata":{},"source":["# Different Regression Model üìâüìâüìâ"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.136081Z","iopub.status.busy":"2023-10-24T13:13:28.135727Z","iopub.status.idle":"2023-10-24T13:13:28.153527Z","shell.execute_reply":"2023-10-24T13:13:28.152169Z","shell.execute_reply.started":"2023-10-24T13:13:28.136044Z"},"trusted":true},"outputs":[],"source":["# Initialize the models with specified hyperparameters\n","LogisticRegression_reg = LogisticRegression(random_state=0, C=0.5, max_iter=50, penalty='l2')\n","svc_reg = SVC(C=1.25, gamma='scale', kernel='rbf')\n","KNeighborsClassifier_reg = KNeighborsClassifier(n_neighbors=9, p=1)  \n","LGBM_reg = LGBMClassifier(random_state=0, learning_rate=0.05, max_depth=12, n_estimators=150)  \n","CatBoost_reg = CatBoostClassifier(random_state=0, learning_rate=0.15, max_depth=8, n_estimators=100)  \n","linear_svc = LinearSVC()\n","decision_tree_reg = DecisionTreeClassifier()\n","random_forest_reg = RandomForestClassifier(max_depth=12, n_estimators=150)\n","xgbc_model_reg = XGBClassifier(learning_rate=0.1, max_depth=4, n_estimators=200)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:28.155678Z","iopub.status.busy":"2023-10-24T13:13:28.155270Z","iopub.status.idle":"2023-10-24T13:13:36.369259Z","shell.execute_reply":"2023-10-24T13:13:36.367808Z","shell.execute_reply.started":"2023-10-24T13:13:28.155645Z"},"trusted":true},"outputs":[],"source":["X_train['AgeGroup'] = X_train['AgeGroup'].astype(int)\n","# Train the models\n","LogisticRegression_reg.fit(X_train, y_train)\n","svc_reg.fit(X_train, y_train)\n","KNeighborsClassifier_reg.fit(X_train, y_train)\n","linear_svc.fit(X_train, y_train)\n","decision_tree_reg.fit(X_train, y_train)\n","LGBM_reg.fit(X_train, y_train)\n","CatBoost_reg.fit(X_train, y_train)\n","random_forest_reg.fit(X_train, y_train)\n","xgbc_model_reg.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:36.371570Z","iopub.status.busy":"2023-10-24T13:13:36.371079Z","iopub.status.idle":"2023-10-24T13:13:39.310612Z","shell.execute_reply":"2023-10-24T13:13:39.309477Z","shell.execute_reply.started":"2023-10-24T13:13:36.371523Z"},"trusted":true},"outputs":[],"source":["X_test['AgeGroup'] = X_test['AgeGroup'].astype(int)\n","# Make predictions using the trained models\n","LogisticRegression_reg_preds = LogisticRegression_reg.predict(X_test)\n","svc_reg_preds = svc_reg.predict(X_test)\n","KNeighborsClassifier_reg_preds = KNeighborsClassifier_reg.predict(X_test)\n","linear_svc_reg_preds = linear_svc.predict(X_test)\n","decision_tree_reg_preds = decision_tree_reg.predict(X_test)\n","LGBM_reg_preds = LGBM_reg.predict(X_test)\n","CatBoost_reg_preds = CatBoost_reg.predict(X_test)\n","random_forest_reg_preds = random_forest_reg.predict(X_test)\n","xgbc_model_reg_preds = xgbc_model_reg.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:39.312669Z","iopub.status.busy":"2023-10-24T13:13:39.312139Z","iopub.status.idle":"2023-10-24T13:13:39.319898Z","shell.execute_reply":"2023-10-24T13:13:39.318652Z","shell.execute_reply.started":"2023-10-24T13:13:39.312624Z"},"trusted":true},"outputs":[],"source":["# Create a DataFrame with predictions\n","predictions_df = pd.DataFrame({\n","#     'Logistic Regression': LogisticRegression_reg_preds,\n","#     'Support Vector Machines': svc_reg_preds,\n","#     'KNN': KNeighborsClassifier_reg_preds,\n","#     'Linear SVC': linear_svc_reg_preds,\n","#     'Decision Tree': decision_tree_reg_preds,\n","#     'LGBM':LGBM_reg_preds,\n","#     'CatBoost_1':CatBoost_reg_preds,\n","    'CatBoost_2':CatBoost_reg_preds,\n","#     'Random Forest': random_forest_reg_preds,\n","#     'XGB Classifier_1': xgbc_model_reg_preds,\n","#     'XGB Classifier_2': xgbc_model_reg_preds\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:39.322297Z","iopub.status.busy":"2023-10-24T13:13:39.321848Z","iopub.status.idle":"2023-10-24T13:13:39.343293Z","shell.execute_reply":"2023-10-24T13:13:39.342050Z","shell.execute_reply.started":"2023-10-24T13:13:39.322257Z"},"trusted":true},"outputs":[],"source":["# Assuming your DataFrame is named 'predictions_df' Calculate the maximum value in each row\n","max_values = predictions_df.sum(axis=1)\n","\n","# Set the answer to 1 if the maximum value in the row is 1, otherwise set it to 0\n","answers = max_values.apply(lambda x: True if x >=1  else False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:39.345475Z","iopub.status.busy":"2023-10-24T13:13:39.345006Z","iopub.status.idle":"2023-10-24T13:13:39.375540Z","shell.execute_reply":"2023-10-24T13:13:39.374211Z","shell.execute_reply.started":"2023-10-24T13:13:39.345433Z"},"trusted":true},"outputs":[],"source":["test_ids = sample_submission['PassengerId']\n","\n","submission_df = pd.DataFrame({'PassengerId': test_ids, 'Transported': answers})\n","\n","# Save the submission DataFrame to a CSV file\n","submission_df.to_csv('submission.csv', index=False)\n","\n","# Print the head of the submission DataFrame\n","print(submission_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-24T13:13:39.378475Z","iopub.status.busy":"2023-10-24T13:13:39.378098Z","iopub.status.idle":"2023-10-24T13:13:39.386099Z","shell.execute_reply":"2023-10-24T13:13:39.384939Z","shell.execute_reply.started":"2023-10-24T13:13:39.378442Z"},"trusted":true},"outputs":[],"source":["# Count the number of 1s and 0s in the 'Survived' column\n","count_ones = submission_df['Transported'].sum()\n","count_zeros = len(submission_df) - count_ones\n","\n","print(\"Number of 1s:\", count_ones)\n","print(\"Number of 0s:\", count_zeros)"]},{"cell_type":"markdown","metadata":{},"source":["# Score: 0.79331 üéØüéØüéØüéØ"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
