{"cells":[{"cell_type":"markdown","metadata":{},"source":["# üì¶ Setting up the Toolkit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.070678Z","iopub.status.busy":"2023-11-02T09:47:12.069432Z","iopub.status.idle":"2023-11-02T09:47:12.086606Z","shell.execute_reply":"2023-11-02T09:47:12.085448Z","shell.execute_reply.started":"2023-11-02T09:47:12.070629Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import re\n","from bs4 import BeautifulSoup\n","import string\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import difflib\n","\n","from sklearn.linear_model import LogisticRegression\n","from wordcloud import WordCloud"]},{"cell_type":"markdown","metadata":{},"source":["# üìä Exploring the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.089440Z","iopub.status.busy":"2023-11-02T09:47:12.088446Z","iopub.status.idle":"2023-11-02T09:47:12.142968Z","shell.execute_reply":"2023-11-02T09:47:12.141759Z","shell.execute_reply.started":"2023-11-02T09:47:12.089396Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('../input/nlp-getting-started/train.csv')\n","test_df = pd.read_csv('../input/nlp-getting-started/test.csv')\n","sample_submission = pd.read_csv(\"../input/nlp-getting-started/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.145295Z","iopub.status.busy":"2023-11-02T09:47:12.144512Z","iopub.status.idle":"2023-11-02T09:47:12.157129Z","shell.execute_reply":"2023-11-02T09:47:12.155891Z","shell.execute_reply.started":"2023-11-02T09:47:12.145258Z"},"trusted":true},"outputs":[],"source":["# train_df.iloc[136:146]\n","train_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.162078Z","iopub.status.busy":"2023-11-02T09:47:12.161635Z","iopub.status.idle":"2023-11-02T09:47:12.175856Z","shell.execute_reply":"2023-11-02T09:47:12.174648Z","shell.execute_reply.started":"2023-11-02T09:47:12.162045Z"},"trusted":true},"outputs":[],"source":["test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.178065Z","iopub.status.busy":"2023-11-02T09:47:12.177249Z","iopub.status.idle":"2023-11-02T09:47:12.196310Z","shell.execute_reply":"2023-11-02T09:47:12.195046Z","shell.execute_reply.started":"2023-11-02T09:47:12.178022Z"},"trusted":true},"outputs":[],"source":["sample_submission.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# üßπ Tidying Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.198303Z","iopub.status.busy":"2023-11-02T09:47:12.197832Z","iopub.status.idle":"2023-11-02T09:47:12.208587Z","shell.execute_reply":"2023-11-02T09:47:12.207433Z","shell.execute_reply.started":"2023-11-02T09:47:12.198267Z"},"trusted":true},"outputs":[],"source":["def convert_to_lower(text):\n","    return text.lower()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.210443Z","iopub.status.busy":"2023-11-02T09:47:12.210102Z","iopub.status.idle":"2023-11-02T09:47:12.221830Z","shell.execute_reply":"2023-11-02T09:47:12.220758Z","shell.execute_reply.started":"2023-11-02T09:47:12.210413Z"},"trusted":true},"outputs":[],"source":["from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import wordnet\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","def woking_in_lemmatize(text):\n","    # Tokenize the input text into words\n","    words = word_tokenize(text)\n","    # Lemmatize the words and remove URLs\n","    lemmatized_words = [lemmatizer.lemmatize(word, wordnet.VERB) for word in words if not word.startswith('http')]\n","    # Join the lemmatized words back into a string\n","    lemmatized_text = ' '.join(lemmatized_words)\n","    return lemmatized_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.223944Z","iopub.status.busy":"2023-11-02T09:47:12.223176Z","iopub.status.idle":"2023-11-02T09:47:12.234764Z","shell.execute_reply":"2023-11-02T09:47:12.233727Z","shell.execute_reply.started":"2023-11-02T09:47:12.223900Z"},"trusted":true},"outputs":[],"source":["def remove_urls(text):\n","    url_pattern = r'https?://\\S+|www\\.\\S+'\n","    processed_text = re.sub(url_pattern, '', text)\n","    return processed_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.236662Z","iopub.status.busy":"2023-11-02T09:47:12.236053Z","iopub.status.idle":"2023-11-02T09:47:12.248607Z","shell.execute_reply":"2023-11-02T09:47:12.247584Z","shell.execute_reply.started":"2023-11-02T09:47:12.236629Z"},"trusted":true},"outputs":[],"source":["def remove_html_tags(text):\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    clean_text = soup.get_text()\n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.250819Z","iopub.status.busy":"2023-11-02T09:47:12.250179Z","iopub.status.idle":"2023-11-02T09:47:12.263552Z","shell.execute_reply":"2023-11-02T09:47:12.262167Z","shell.execute_reply.started":"2023-11-02T09:47:12.250789Z"},"trusted":true},"outputs":[],"source":["def remove_emojis(text):\n","    emoji_pattern = re.compile(\n","        \"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n","        u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n","        u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n","        u\"\\U0001F700-\\U0001F77F\"  # Alphabetic presentation forms\n","        u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes\n","        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n","        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental symbols and pictographs\n","        u\"\\U0001FA00-\\U0001FA6F\"  # Chess symbols\n","        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and pictographs for Zodiac signs\n","        u\"\\U0001F700-\\U0001F77F\"  # Glag symbols\n","        u\"\\U0001F780-\\U0001F7FF\"  # Weather symbols\n","        u\"\\U0001F880-\\U0001F8FF\"  # Supplemental arrows-A\n","        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous symbols\n","        u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n","        \"]+\",\n","        flags=re.UNICODE,\n","    )\n","    clean_text = emoji_pattern.sub(r\"\", text)\n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.266056Z","iopub.status.busy":"2023-11-02T09:47:12.264860Z","iopub.status.idle":"2023-11-02T09:47:12.278523Z","shell.execute_reply":"2023-11-02T09:47:12.277350Z","shell.execute_reply.started":"2023-11-02T09:47:12.266014Z"},"trusted":true},"outputs":[],"source":["def remove_multiple_spaces(text):\n","    # Regular expression pattern to match multiple spaces\n","    space_pattern = r'\\s+'\n","    # Replace multiple spaces with a single space\n","    clean_text = re.sub(space_pattern, ' ', text)\n","    return clean_text.strip()  # Remove leading and trailing spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.284314Z","iopub.status.busy":"2023-11-02T09:47:12.283924Z","iopub.status.idle":"2023-11-02T09:47:12.292032Z","shell.execute_reply":"2023-11-02T09:47:12.290833Z","shell.execute_reply.started":"2023-11-02T09:47:12.284284Z"},"trusted":true},"outputs":[],"source":["def remove_timestamps(text):\n","    # Regular expression pattern to match timestamps like [01:04 UTC]\n","    timestamp_pattern = r'\\[\\d{2}:\\d{2} [A-Za-z]{3}\\]'\n","    # Remove timestamps from the text\n","    clean_text = re.sub(timestamp_pattern, '', text)\n","    return clean_text.strip()  # Remove leading and trailing spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.294872Z","iopub.status.busy":"2023-11-02T09:47:12.293522Z","iopub.status.idle":"2023-11-02T09:47:12.306056Z","shell.execute_reply":"2023-11-02T09:47:12.305049Z","shell.execute_reply.started":"2023-11-02T09:47:12.294835Z"},"trusted":true},"outputs":[],"source":["def remove_punctuations_and_timestamps(text):\n","    # Remove punctuations\n","    text_without_punctuations = text.translate(str.maketrans('', '', string.punctuation))\n","    \n","    # Regular expression pattern to match timestamps like [01:04 UTC]\n","    timestamp_pattern = r'\\[\\d{2}:\\d{2} [A-Za-z]{3}\\]'\n","    # Remove timestamps from the text\n","    text_without_timestamps = re.sub(timestamp_pattern, '', text_without_punctuations)\n","    \n","    return text_without_timestamps.strip()  # Remove leading and trailing spaces"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.307890Z","iopub.status.busy":"2023-11-02T09:47:12.307391Z","iopub.status.idle":"2023-11-02T09:47:12.324666Z","shell.execute_reply":"2023-11-02T09:47:12.323153Z","shell.execute_reply.started":"2023-11-02T09:47:12.307857Z"},"trusted":true},"outputs":[],"source":["def remove_special_characters(text):\n","    # Remove non-alphanumeric characters and whitespace\n","    clean_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.327544Z","iopub.status.busy":"2023-11-02T09:47:12.326060Z","iopub.status.idle":"2023-11-02T09:47:12.339608Z","shell.execute_reply":"2023-11-02T09:47:12.337762Z","shell.execute_reply.started":"2023-11-02T09:47:12.327507Z"},"trusted":true},"outputs":[],"source":["def remove_english_words(text):\n","    # Tokenize the input text into words\n","    words = word_tokenize(text)\n","    \n","    # Get the list of English stop words\n","    stop_words = set(stopwords.words('english'))\n","    \n","    stop_updated = stop_words\n","    # Remove common words from the text\n","    filtered_words = [word for word in words if word.lower() not in stop_words]\n","    \n","    # Join the filtered words back into a string\n","    clean_text = ' '.join(filtered_words)\n","    return clean_text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.342358Z","iopub.status.busy":"2023-11-02T09:47:12.341635Z","iopub.status.idle":"2023-11-02T09:47:12.354906Z","shell.execute_reply":"2023-11-02T09:47:12.353652Z","shell.execute_reply.started":"2023-11-02T09:47:12.342309Z"},"trusted":true},"outputs":[],"source":["replacements = {\n","    \"they'd\": \"they would\",\n","    \"haven't\": \"have not\",\n","    \"hasn't\": \"has not\",\n","    \"hadn't\": \"had not\",\n","    \"don't\": \"do not\",\n","    \"doesn't\": \"does not\",\n","    \"didn't\": \"did not\",\n","    \"can't\": \"cannot\",\n","    \"won't\": \"will not\",\n","    \"wouldn't\": \"would not\",\n","    \"shouldn't\": \"should not\",\n","    \"mightn't\": \"might not\",\n","    \"mustn't\": \"must not\",\n","    \"aren't\": \"are not\",\n","    \"isn't\": \"is not\",\n","    \"wasn't\": \"was not\",\n","    \"weren't\": \"were not\",\n","    \"he's\": \"he is\",\n","    \"she's\": \"she is\",\n","    \"it's\": \"it is\",\n","    \"I'm\": \"I am\",\n","    \"you're\": \"you are\",\n","    \"we're\": \"we are\",\n","    \"they're\": \"they are\",\n","    \"he'll\": \"he will\",\n","    \"she'll\": \"she will\",\n","    \"it'll\": \"it will\",\n","    \"i'll\": \"i will\",\n","    \"you'll\": \"you will\",\n","    \"we'll\": \"we will\",\n","    \"they'll\": \"they will\",\n","    \"he'd\": \"he would\",\n","    \"she'd\": \"she would\",\n","    \"it'd\": \"it would\",\n","    \"i'd\": \"i would\",\n","    \"you'd\": \"you would\",\n","    \"we'd\": \"we would\",\n","}\n","def convert_short_full_form(text):\n","    for short_form, full_form in replacements.items():\n","        text = text.replace(short_form, full_form)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:12.356983Z","iopub.status.busy":"2023-11-02T09:47:12.356648Z","iopub.status.idle":"2023-11-02T09:47:16.428954Z","shell.execute_reply":"2023-11-02T09:47:16.427651Z","shell.execute_reply.started":"2023-11-02T09:47:12.356955Z"},"trusted":true},"outputs":[],"source":["train_df[\"text\"]=train_df[\"text\"].apply(lambda x : convert_to_lower(x))\n","# train_df[\"text\"]=train_df[\"text\"].apply(lambda x : woking_in_lemmatize(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_urls(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : convert_short_full_form(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_html_tags(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_emojis(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_timestamps(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_punctuations_and_timestamps(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_special_characters(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_english_words(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_multiple_spaces(x))\n","train_df[\"text\"].iloc[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:16.430862Z","iopub.status.busy":"2023-11-02T09:47:16.430502Z","iopub.status.idle":"2023-11-02T09:47:18.229036Z","shell.execute_reply":"2023-11-02T09:47:18.227776Z","shell.execute_reply.started":"2023-11-02T09:47:16.430829Z"},"trusted":true},"outputs":[],"source":["test_df[\"text\"]=test_df[\"text\"].apply(lambda x : convert_to_lower(x))\n","# test_df[\"text\"]=test_df[\"text\"].apply(lambda x : woking_in_lemmatize(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_urls(x))\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : convert_short_full_form(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_html_tags(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_emojis(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_timestamps(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_punctuations_and_timestamps(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_special_characters(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_english_words(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_multiple_spaces(x))\n","test_df[\"text\"].iloc[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:18.231624Z","iopub.status.busy":"2023-11-02T09:47:18.231180Z","iopub.status.idle":"2023-11-02T09:47:18.244634Z","shell.execute_reply":"2023-11-02T09:47:18.243245Z","shell.execute_reply.started":"2023-11-02T09:47:18.231582Z"},"trusted":true},"outputs":[],"source":["train_df.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:18.247113Z","iopub.status.busy":"2023-11-02T09:47:18.246557Z","iopub.status.idle":"2023-11-02T09:47:18.264271Z","shell.execute_reply":"2023-11-02T09:47:18.263010Z","shell.execute_reply.started":"2023-11-02T09:47:18.247057Z"},"trusted":true},"outputs":[],"source":["test_df.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# REMOVE COMMAN WORDS"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:18.266642Z","iopub.status.busy":"2023-11-02T09:47:18.265997Z","iopub.status.idle":"2023-11-02T09:47:20.508827Z","shell.execute_reply":"2023-11-02T09:47:20.507688Z","shell.execute_reply.started":"2023-11-02T09:47:18.266609Z"},"trusted":true},"outputs":[],"source":["from wordcloud import WordCloud\n","reviews_combined = \" \".join(train_df.text.values)\n","word_cloud = WordCloud(width=800,height=800,background_color='white',max_words=50).\\\n","generate_from_text(reviews_combined)\n","plt.figure(figsize=[8,8])\n","plt.imshow(word_cloud)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:20.510918Z","iopub.status.busy":"2023-11-02T09:47:20.510476Z","iopub.status.idle":"2023-11-02T09:47:21.092274Z","shell.execute_reply":"2023-11-02T09:47:21.090981Z","shell.execute_reply.started":"2023-11-02T09:47:20.510878Z"},"trusted":true},"outputs":[],"source":["reviews_combined = ' '.join(train_df[train_df['target']==1]['text'])\n","\n","all_terms = []\n","fdist = {}\n","all_terms = reviews_combined.lower().split(\" \")\n","for word in all_terms:\n","    fdist[word] = fdist.get(word,0) + 1\n","    \n","    \n","freq = {\"words\":list(fdist.keys()),\"freq\":list(fdist.values())}\n","df_dist = pd.DataFrame(freq)\n","\n","df_dist.sort_values(ascending=False, by=\"freq\").head(25).\\\n","plot.bar(x= \"words\", y= \"freq\",figsize=(20,5)) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:21.094534Z","iopub.status.busy":"2023-11-02T09:47:21.094170Z","iopub.status.idle":"2023-11-02T09:47:21.659644Z","shell.execute_reply":"2023-11-02T09:47:21.658324Z","shell.execute_reply.started":"2023-11-02T09:47:21.094502Z"},"trusted":true},"outputs":[],"source":["reviews_combined2 = ' '.join(train_df[train_df['target']==0]['text'])\n","\n","all_terms2 = []\n","fdist2 = {}\n","all_terms2 = reviews_combined2.lower().split(\" \")\n","for word in all_terms2:\n","    fdist2[word] = fdist2.get(word,0) + 1\n","    \n","\n","freq2 = {\"words\":list(fdist2.keys()),\"freq\":list(fdist2.values())}\n","df_dist2 = pd.DataFrame(freq2)\n","\n","\n","df_dist2.sort_values(ascending=False, by=\"freq\").head(25).\\\n","plot.bar(x= \"words\", y= \"freq\",figsize=(20,5)) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:21.661496Z","iopub.status.busy":"2023-11-02T09:47:21.660829Z","iopub.status.idle":"2023-11-02T09:47:21.673820Z","shell.execute_reply":"2023-11-02T09:47:21.672646Z","shell.execute_reply.started":"2023-11-02T09:47:21.661464Z"},"trusted":true},"outputs":[],"source":["# Get the top 25 words from df_dist and df_dist2\n","top_words_df_dist = set(df_dist.sort_values(ascending=False, by=\"freq\").head(25)[\"words\"])\n","top_words_df_dist2 = set(df_dist2.sort_values(ascending=False, by=\"freq\").head(25)[\"words\"])\n","\n","# Find the common words\n","common_words = top_words_df_dist.intersection(top_words_df_dist2)\n","\n","# Number of common words\n","num_common_words = len(common_words)\n","\n","print(\"Number of common words in top 25: \", num_common_words)\n","print(\"Common words in top 25: \", common_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:21.676317Z","iopub.status.busy":"2023-11-02T09:47:21.675277Z","iopub.status.idle":"2023-11-02T09:47:21.868995Z","shell.execute_reply":"2023-11-02T09:47:21.867609Z","shell.execute_reply.started":"2023-11-02T09:47:21.676272Z"},"trusted":true},"outputs":[],"source":["def remove_comman_words(text):\n","    words_to_remove = ['time', 'new','via', 'like' , '2', 'us' , 'people']\n","    letters_to_remove = r'\\b[a-z]\\b'\n","    \n","    for word in words_to_remove:\n","        text = text.replace(word, '')\n","\n","    text = re.sub(letters_to_remove, '', text, flags=re.IGNORECASE)\n","\n","    return text\n","\n","train_df['text'] = train_df['text'].apply(remove_comman_words)\n","test_df['text'] = test_df['text'].apply(remove_comman_words)\n","train_df[\"text\"]=train_df[\"text\"].apply(lambda x : remove_multiple_spaces(x))\n","test_df[\"text\"]=test_df[\"text\"].apply(lambda x : remove_multiple_spaces(x))"]},{"cell_type":"markdown","metadata":{},"source":["# ü§ñ Building Models and Making Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:21.871049Z","iopub.status.busy":"2023-11-02T09:47:21.870599Z","iopub.status.idle":"2023-11-02T09:47:22.244402Z","shell.execute_reply":"2023-11-02T09:47:22.243162Z","shell.execute_reply.started":"2023-11-02T09:47:21.871009Z"},"trusted":true},"outputs":[],"source":["X_train = train_df['text']\n","Y_train = train_df['target']\n","\n","vectorizer = CountVectorizer(max_features=5000, stop_words='english')\n","X_train_vec = vectorizer.fit_transform(X_train)\n","\n","model = LogisticRegression()\n","model.fit(X_train_vec, Y_train)\n","\n","X_test = test_df['text']\n","X_test_ids = test_df[\"id\"]\n","\n","# Vectorize the test data using the corresponding vectorizer\n","X_test_vec = vectorizer.transform(X_test)\n","\n","predictions = model.predict(X_test_vec)\n","predictions_data = []\n","predictions_data.extend(zip(X_test_ids, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["# üì§ Final Deliverable"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-02T09:47:22.246385Z","iopub.status.busy":"2023-11-02T09:47:22.245992Z","iopub.status.idle":"2023-11-02T09:47:22.287731Z","shell.execute_reply":"2023-11-02T09:47:22.286469Z","shell.execute_reply.started":"2023-11-02T09:47:22.246354Z"},"trusted":true},"outputs":[],"source":["# Create a DataFrame from predictions_data\n","predictions_df = pd.DataFrame(predictions_data, columns=['id', 'target'])\n","\n","# Save predictions to a CSV file\n","predictions_df.to_csv('submission.csv', index=False)\n","\n","print(\"Predictions saved to predictions.csv\")\n","\n","predictions_df"]},{"cell_type":"markdown","metadata":{},"source":["# üìäüèÜ Performance Evaluation - Score : 0.79190"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
